---
layout:     post
title:     Spark 自动合并小文件
date:       2020-07-03
author:     jiulongzhu
header-img: img/moon_night.jpg
catalog: true
tags:
    -  Spark 2.3.0
    -  方案
---

Spark SQL/DataFrame application 在高并发度或使用动态分区时产生大量小文件的平台化治理实践。  

<!-- more -->   

## 背景  
spark application 至少会输出 spark.sql.shuffle.partitions(默认 200) 个文件，如果开启了动态分区则更多。    
一般情况下数据开发可以通过 repartition/coalesce 或/**+ COALESCE/REPARTITION(numPartitions) */ 来控制输出文件数量，但数据通过 filter、flatmap、join、group by 等算子之后难以根据输入数据量级来估算输出数据量级，且实际输出文件大小还会受到数据本身、文件格式和压缩算法的影响。在某些场景下，例如医院科室和疾病类型重复率较高导致数据压缩率极高 输出文件并不大。  
更多数情况下会设置高 spark.sql.shuffle.partitions 以增加并发度或避免可能出现的 reduce 端 OOM。因此从 application 内部通过设置分区数的方式来控制输出文件数量十分困难，至于 SQL application 则更难做到。      

小文件过多的负面影响主要是增大了 HDFS namenode/datanode 的内存负载及检索速度，其次是降低了碎片文件寻址速度 增加读取成本。  

面临的困境主要是，线上表绝大部分是由 SQL 产出的，手动合并 hdfs 目录的成本极高。因此希望能在 Spark 源代码上做一些二次开发能够自动合并 application 产出的小文件。   

## 思路 
主要考虑了以下问题:  

1. 有办法获取最后一个 ShuffleMapStage 各个分区的输入数据量和条数，但是最后一个 ShuffleMapStage 后续可能有 filter、flatmap 等操作，因此无法在 application 未写出数据时，按照输入数据量和压缩方式预估出分区输出文件大小。因而只能在 application 写出数据时或写出后判断及合并输出文件。     
2. 无法在数据写出后通过优化策略修改当前执行计划，相当于在已经执行完成的执行计划树上加节点，且数据写入完成后无法通过当前执行计划的 DataWritingCommand 再操作数据(Seq.empty[Row])。   
3. 可选的方式有两种: 一、在当前执行计划的数据写出阶段(临时数据写出完成但是还未移动到最终目录)做合并操作 二、在当前执行计划的数据写出阶段结束后拉起一个合并操作。本质上差不多,但是第二种方式会造成额外的元数据修改操作，例如在 spark catalog 中 refresh table、uncache table 以及更新 statistics 数据。故选择第一种方式。             
4. 在数据写出后，执行合并操作然后再写出数据属于递归操作，需要仔细设置终止条件。        
5. 当文件数量较少时无需合并(e.g. 一个分区只有两个小文件)，为减少合并任务的启动成本可以允许存在少量小文件; 使用压缩率较高的算法时，无需将文件大小严格合并到 dfs.blocksize，会导致后续任务读取解压该文件时 OOM。暂取0.25 * dfs.blocksize  
6. Spark 内置的写数据方式(物理计划)有五种: CreateHiveTableAsSelectCommand,InsertIntoHiveDirCommand,InsertIntoHiveTable,CreateDataSourceTableAsSelectCommand,InsertIntoHadoopFsRelation，但最终都是在 FileFormatWriter 定义 task、构建 Spark Job 来实现写入的。CreateHiveTableAsSelectCommand 内部复用了 InsertIntoHiveDirCommand,CreateDataSourceTableAsSelectCommand 复用了 InsertIntoHadooopFsRelation; InsertIntoHiveDirCommand 和 InsertIntoHiveTable 都继承自 SaveAsHiveTable 接口，接口内 saveAsHiveFile方法使用 FileFormatWriter 写出数据返回并返回受写出操作影响的分区名称。在 SaveAsHiveTable 接口内添加合并 hive 小文件逻辑影响的范围是 CreateHiveTableAsSelectCommand(对应语法 create table tbl_name as select statement)、InsertIntoHiveDirCommand(对应语法 insert overwrite directory path row formatted .. select statement)和 InsertIntoHiveTable(对应语法 insert into/overwrite table tbl_name partition(...) select statement)，正是 hive 数据源数据写入的所有操作方式。开源大佬设计模式用的真好。InsertIntoHadooopFsRelation 对应 DataFrame 编程中 df.write.format(source).saveAsTable(...) 或 df.write.orc(hdfs path) 两种写入方式。               

## 设计  

![Spark 自动合并小文件流程](/img/pictures/spark/auto_merge_small_file.png)  


| 参数名  | 默认值  | 功能 |
|:------------- |:---------------|:-------------|
|spark.hive.automerge.enabled|true|是否开启自动合并小文件功能|
|spark.hive.automerge.least.filenum|3|分区内文件数小于此值时,不合并小文件(考虑启动任务成本)|
|spark.hive.automerge.block.percent|0.25|合并后文件的理想大小是 dfs.blocksize 与此参数的乘积(考虑压缩率)|     
|spark.hive.automerge.shuffle.enabled|false|重分区时是否开启 shuffle。true 时为 repartition，false 时为coalesce|

> 测试效果样例  
1. 日志信息   
INFO MergeHiveSmallFileUtil: merge table: user_profile.dwd_user_profile_di ,partition:second=visit/third=visit_7d finished, cost 164 ms.before {total length in bytes: 233 ,file number: 3} ,after {file number: 1}    
2. Spark History EventLog   
{"Event":"org.apache.spark.sql.hive.execution.AutoMergeSmallFileEvent","table":"user_profile.dwd_user_profile_di","part":"second=visit/third=visit_7d","totalLenInByte":233,"numBefore":3,"numAfter":1,"diff":2,"costInMillSec":164}    


## todo 

1. 临时文件以 Hive TableDesc 定义的 output format(e.g. org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat) 形式写出，但是无法用 TableDesc定义的 input format来读取。因为 Hive TableDesc 定义的 input/output format 不是一个可用的 Spark SQL DataSource。使用 sparkSession.read.option("inputFormat",TableDesc.getInputFormatClassName).option('outputformat',TableDesc.getOutputFormatClassName)也无法解决此问题，因为 spark 默认的 DataSource 为 parquet。没有在源代码中找到更优雅的方式来映射 Hive output format 到 Spark SQL DataSource，求助于 spark dev list 也未收到回复，目前采用的是死板的枚举映射判断 Hive outputformat 的后缀(e.g. orcoutputformat->orc)。  
2. 这套合并小文件逻辑稍作修改就可以扩展为 "对指定表或分区进行小文件合并"，扩展 Spark SQL 支持的语法糖，但是由于我对 antlr 语法十分陌生，未敢妄动。      
3. 在线上灰度一定时间后，将通过 SparkListenerEvent 统计出的信息和 hdfs namenode 平均文件大小来评估具体效果。  


  


   
